{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Análise de Sentimentos – reviews_Clothing_Shoes_and_Jewelry Amazon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from pymongo import MongoClient\n",
    "from imblearn.under_sampling import RandomUnderSampler \n",
    "from collections import Counter\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Criando uma conexão com o MongoDB**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MongoClient(host=['localhost:27017'], document_class=dict, tz_aware=False, connect=True)\n"
     ]
    }
   ],
   "source": [
    "client = MongoClient()\n",
    "print (client)\n",
    "db = client.amazon\n",
    "clothing = db.clothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lê arquivo de dados e conta a quantidade de linhas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_id               278675\n",
       "reviewerID        278675\n",
       "asin              278675\n",
       "reviewerName      278223\n",
       "helpful           278675\n",
       "reviewText        278675\n",
       "overall           278675\n",
       "summary           278675\n",
       "unixReviewTime    278675\n",
       "reviewTime        278675\n",
       "classification    278675\n",
       "dtype: int64"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getDF():\n",
    "    i = 0\n",
    "    df = {}\n",
    "    for d in clothing.find():\n",
    "        df[i] = d\n",
    "        i += 1\n",
    "    return pd.DataFrame.from_dict(df, orient='index')\n",
    "\n",
    "dataset = getDF()\n",
    "\n",
    "dataset.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conta a quantidade de linhas de reviews neutros, positivos e negativos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_id               30425\n",
       "reviewerID        30425\n",
       "asin              30425\n",
       "reviewerName      30387\n",
       "helpful           30425\n",
       "reviewText        30425\n",
       "overall           30425\n",
       "summary           30425\n",
       "unixReviewTime    30425\n",
       "reviewTime        30425\n",
       "classification    30425\n",
       "dtype: int64"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[dataset.classification=='Neutral'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_id               221595\n",
       "reviewerID        221595\n",
       "asin              221595\n",
       "reviewerName      221226\n",
       "helpful           221595\n",
       "reviewText        221595\n",
       "overall           221595\n",
       "summary           221595\n",
       "unixReviewTime    221595\n",
       "reviewTime        221595\n",
       "classification    221595\n",
       "dtype: int64"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[dataset.classification=='Positive'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_id               26655\n",
       "reviewerID        26655\n",
       "asin              26655\n",
       "reviewerName      26610\n",
       "helpful           26655\n",
       "reviewText        26655\n",
       "overall           26655\n",
       "summary           26655\n",
       "unixReviewTime    26655\n",
       "reviewTime        26655\n",
       "classification    26655\n",
       "dtype: int64"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[dataset.classification=='Negative'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Separando reviews e suas classes\n",
    "**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reviews = dataset['reviewText'].values\n",
    "\n",
    "classifications = dataset['classification'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Random under-sampling **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape Counter({'Positive': 221595, 'Neutral': 30425, 'Negative': 26655})\n",
      "Resampled dataset shape Counter({'Negative': 26655, 'Neutral': 26655, 'Positive': 26655})\n"
     ]
    }
   ],
   "source": [
    "print('Original dataset shape {}'.format(Counter(classifications)))\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(reviews)\n",
    "\n",
    "reviews_transformed = le.transform(reviews).reshape(-1, 1)\n",
    "\n",
    "rus = RandomUnderSampler()\n",
    "X_res, y_res = rus.fit_sample(reviews_transformed, classifications)\n",
    "\n",
    "print('Resampled dataset shape {}'.format(Counter(y_res)))\n",
    "\n",
    "reviews = le.inverse_transform(X_res)\n",
    "classifications = y_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Pre-Processamento **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def PreprocessamentoSemStopWords(instancia):\n",
    "    # remove links, pontos, virgulas, ponto e virgulas dos reviews\n",
    "    # coloca tudo em minusculo\n",
    "    # remove stopwords\n",
    "    instancia = re.sub(r\"http\\S+\", \"\", instancia).lower().replace(',','').replace('.','').replace(';','').replace('-','')\n",
    "    stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "    palavras = [i for i in instancia.split() if not i in stopwords]\n",
    "    return (\" \".join(palavras))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Stemming(instancia):\n",
    "    stemmer = nltk.stem.RSLPStemmer()\n",
    "    palavras=[]\n",
    "    for w in instancia.split():\n",
    "        palavras.append(stemmer.stem(w))\n",
    "    return (\" \".join(palavras))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3yr old loved tutu skirt pink! hoping order different colorsshe hardly used thisthe stitching came apart 2weeksnow it's lying closetaltogether wore like 45 times 20 mins sowish stitching better quality hold little ones wear can't recommend\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"3yr old loved tutu skirt pink! hoping ord different colorssh hardly used thisth stitching cam apart 2weeksnow it' lying closetaltogeth wor lik 45 tim 20 mim sowish stitching bett quality hold littl one we can't recommend\""
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instancia = \"My 3yr old loved this tutu skirt in pink! Was hoping to order more in different colors.She had hardly used this,the stitching came apart in 2weeks.now it's lying in her closet..Altogether she wore it like 4-5 times for 20 mins or so.wish the stitching was of better quality to hold up while little ones wear it. Can't recommend.\"\n",
    "\n",
    "instancia = PreprocessamentoSemStopWords(instancia)\n",
    "\n",
    "print(instancia)\n",
    "\n",
    "Stemming(instancia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "\n",
    "for r in reviews:\n",
    "    text = ''.join(map(str, r));\n",
    "    text = PreprocessamentoSemStopWords(text)\n",
    "    reviews[i] = Stemming(text)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Gerando o modelo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(analyzer=\"word\")\n",
    "freq_reviews = vectorizer.fit_transform(reviews.ravel())\n",
    "modelo = MultinomialNB()\n",
    "modelo.fit(freq_reviews, classifications)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Testando o modelo com algumas instâncias simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Definindo instâncias de teste dentro de uma lista\n",
    "\n",
    "#Neutral\n",
    "#Positive\n",
    "#Negative\n",
    "#Neutral\n",
    "\n",
    "testes = [\"My 3yr old loved this tutu skirt in pink! Was hoping to order more in different colors.She had hardly used this,the stitching came apart in 2weeks.now it's lying in her closet..Altogether she wore it like 4-5 times for 20 mins or so.wish the stitching was of better quality to hold up while little ones wear it. Can't recommend.\",\n",
    "         \"What can I say... my daughters have it in orange, black, white and pink and I am thinking to buy for they the fuccia one. It is a very good way for exalt a dancer outfit: great colors, comfortable, looks great, easy to wear, durables and little girls love it. I think it is a great buy for costumer and play too.\",\n",
    "        \"Never GOT this item - but gave a 1 STAR because the replies from the SUPPLIER was GREAT.They tried to send the item more than once.My $ was refunded in a timely manner too.It was a shame I never got it for my daughter - it would of looked great with her OUTFIT for Dr. Seuss WEEK at school.Most original.Maybe next time.\", \n",
    "       \"I already own this particular Shining Image jewelry box in brown, so this was my second buy. It arrived with some of the leather scratched, even though it looked like I was the first one opening the box. This particular color pink also looked pretty bad in person. The quality of this box seemed lesser than the brown one I own.I returned this pink case for a refund without a problem.  Got another brown Shining Image jewelry case and it's fine!\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "\n",
    "for t in testes:\n",
    "    result = PreprocessamentoSemStopWords(t)\n",
    "    testes[i] = Stemming(result)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "freq_testes = vectorizer.transform(testes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fazendo a classificação com o modelo treinado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Neutral', 'Positive', 'Negative', 'Negative'],\n",
       "      dtype='<U8')"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo.predict(freq_testes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Avaliando o modelo **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fazendo o cross validation do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resultados = cross_val_predict(modelo, freq_reviews, classifications, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Medindo a acurácia média do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.64694553867316951"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(classifications,resultados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Medidas de validação do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Positive       0.74      0.75      0.75     26655\n",
      "   Negative       0.68      0.60      0.64     26655\n",
      "    Neutral       0.53      0.58      0.56     26655\n",
      "\n",
      "avg / total       0.65      0.65      0.65     79965\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentimento=['Positive','Negative','Neutral']\n",
    "print (metrics.classification_report(classifications,resultados,sentimento))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Matriz de confusão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted  Negative  Neutral  Positive    All\n",
      "True                                         \n",
      "Negative      16115     8486      2054  26655\n",
      "Neutral        6209    15591      4855  26655\n",
      "Positive       1413     5215     20027  26655\n",
      "All           23737    29292     26936  79965\n"
     ]
    }
   ],
   "source": [
    "print(pd.crosstab(classifications, resultados, rownames=['True'], colnames=['Predicted'], margins=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Melhorando resultados com Bigrams**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(1,2))\n",
    "freq_reviews = vectorizer.fit_transform(reviews.ravel())\n",
    "modelo = MultinomialNB()\n",
    "modelo.fit(freq_reviews,classifications)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resultados = cross_val_predict(modelo, freq_reviews, classifications, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.663552804351904"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(classifications,resultados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Positive       0.78      0.76      0.77     26655\n",
      "   Negative       0.70      0.61      0.65     26655\n",
      "    Neutral       0.54      0.62      0.58     26655\n",
      "\n",
      "avg / total       0.67      0.66      0.67     79965\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentimento=['Positive','Negative','Neutral']\n",
    "print (metrics.classification_report(classifications,resultados,sentimento))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predito   Negative  Neutral  Positive    All\n",
      "Real                                        \n",
      "Negative     16355     8698      1602  26655\n",
      "Neutral       6009    16448      4198  26655\n",
      "Positive      1160     5237     20258  26655\n",
      "All          23524    30383     26058  79965\n"
     ]
    }
   ],
   "source": [
    "print (pd.crosstab(classifications, resultados, rownames=['Real'], colnames=['Predito'], margins=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Análise de Sentimentos – reviews_Clothing_Shoes_and_Jewelry Amazon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from pymongo import MongoClient\n",
    "from imblearn.under_sampling import RandomUnderSampler \n",
    "from collections import Counter\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Criando uma conexão com o MongoDB**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MongoClient(host=['localhost:27017'], document_class=dict, tz_aware=False, connect=True)\n"
     ]
    }
   ],
   "source": [
    "client = MongoClient()\n",
    "print (client)\n",
    "db = client.amazon\n",
    "clothing = db.clothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lê arquivo de dados e conta a quantidade de linhas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_id               278677\n",
       "reviewerID        278677\n",
       "asin              278677\n",
       "reviewerName      278225\n",
       "helpful           278677\n",
       "reviewText        278677\n",
       "overall           278677\n",
       "summary           278677\n",
       "unixReviewTime    278677\n",
       "reviewTime        278677\n",
       "classification    278677\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getDF():\n",
    "    i = 0\n",
    "    df = {}\n",
    "    for d in clothing.find():\n",
    "        df[i] = d\n",
    "        i += 1\n",
    "    return pd.DataFrame.from_dict(df, orient='index')\n",
    "\n",
    "dataset = getDF()\n",
    "\n",
    "dataset.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conta a quantidade de linhas de reviews neutros, positivos e negativos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_id               30425\n",
       "reviewerID        30425\n",
       "asin              30425\n",
       "reviewerName      30387\n",
       "helpful           30425\n",
       "reviewText        30425\n",
       "overall           30425\n",
       "summary           30425\n",
       "unixReviewTime    30425\n",
       "reviewTime        30425\n",
       "classification    30425\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[dataset.classification=='Neutral'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_id               221597\n",
       "reviewerID        221597\n",
       "asin              221597\n",
       "reviewerName      221228\n",
       "helpful           221597\n",
       "reviewText        221597\n",
       "overall           221597\n",
       "summary           221597\n",
       "unixReviewTime    221597\n",
       "reviewTime        221597\n",
       "classification    221597\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[dataset.classification=='Positive'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_id               26655\n",
       "reviewerID        26655\n",
       "asin              26655\n",
       "reviewerName      26610\n",
       "helpful           26655\n",
       "reviewText        26655\n",
       "overall           26655\n",
       "summary           26655\n",
       "unixReviewTime    26655\n",
       "reviewTime        26655\n",
       "classification    26655\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[dataset.classification=='Negative'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Separando reviews e suas classes\n",
    "**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reviews = dataset['reviewText'].values\n",
    "\n",
    "classifications = dataset['classification'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Random under-sampling **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape Counter({'Positive': 221597, 'Neutral': 30425, 'Negative': 26655})\n",
      "Resampled dataset shape Counter({'Negative': 26655, 'Neutral': 26655, 'Positive': 26655})\n"
     ]
    }
   ],
   "source": [
    "print('Original dataset shape {}'.format(Counter(classifications)))\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(reviews)\n",
    "\n",
    "reviews_transformed = le.transform(reviews).reshape(-1, 1)\n",
    "\n",
    "rus = RandomUnderSampler()\n",
    "X_res, y_res = rus.fit_sample(reviews_transformed, classifications)\n",
    "\n",
    "print('Resampled dataset shape {}'.format(Counter(y_res)))\n",
    "\n",
    "reviews = le.inverse_transform(X_res)\n",
    "classifications = y_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Pre-Processamento **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def PreprocessamentoSemStopWords(instancia):\n",
    "    # remove links, pontos, virgulas, ponto e virgulas dos reviews\n",
    "    # coloca tudo em minusculo\n",
    "    # remove stopwords\n",
    "    instancia = re.sub(r\"http\\S+\", \"\", instancia).lower().replace(',','').replace('.','').replace(';','').replace('-','')\n",
    "    stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "    palavras = [i for i in instancia.split() if not i in stopwords]\n",
    "    return (\" \".join(palavras))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Stemming(instancia):\n",
    "    stemmer = nltk.stem.RSLPStemmer()\n",
    "    palavras=[]\n",
    "    for w in instancia.split():\n",
    "        palavras.append(stemmer.stem(w))\n",
    "    return (\" \".join(palavras))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3yr old loved tutu skirt pink! hoping order different colorsshe hardly used thisthe stitching came apart 2weeksnow it's lying closetaltogether wore like 45 times 20 mins sowish stitching better quality hold little ones wear can't recommend\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"3yr old loved tutu skirt pink! hoping ord different colorssh hardly used thisth stitching cam apart 2weeksnow it' lying closetaltogeth wor lik 45 tim 20 mim sowish stitching bett quality hold littl one we can't recommend\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instancia = \"My 3yr old loved this tutu skirt in pink! Was hoping to order more in different colors.She had hardly used this,the stitching came apart in 2weeks.now it's lying in her closet..Altogether she wore it like 4-5 times for 20 mins or so.wish the stitching was of better quality to hold up while little ones wear it. Can't recommend.\"\n",
    "\n",
    "instancia = PreprocessamentoSemStopWords(instancia)\n",
    "\n",
    "print(instancia)\n",
    "\n",
    "Stemming(instancia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "\n",
    "for r in reviews:\n",
    "    text = ''.join(map(str, r));\n",
    "    text = PreprocessamentoSemStopWords(text)\n",
    "    reviews[i] = Stemming(text)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Gerando o modelo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(analyzer=\"word\")\n",
    "freq_reviews = vectorizer.fit_transform(reviews.ravel())\n",
    "modelo = MultinomialNB()\n",
    "modelo.fit(freq_reviews, classifications)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Testando o modelo com algumas instâncias simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Definindo instâncias de teste dentro de uma lista\n",
    "\n",
    "#Neutral\n",
    "#Positive\n",
    "#Negative\n",
    "#Neutral\n",
    "\n",
    "testes = [\"My 3yr old loved this tutu skirt in pink! Was hoping to order more in different colors.She had hardly used this,the stitching came apart in 2weeks.now it's lying in her closet..Altogether she wore it like 4-5 times for 20 mins or so.wish the stitching was of better quality to hold up while little ones wear it. Can't recommend.\",\n",
    "         \"What can I say... my daughters have it in orange, black, white and pink and I am thinking to buy for they the fuccia one. It is a very good way for exalt a dancer outfit: great colors, comfortable, looks great, easy to wear, durables and little girls love it. I think it is a great buy for costumer and play too.\",\n",
    "        \"Never GOT this item - but gave a 1 STAR because the replies from the SUPPLIER was GREAT.They tried to send the item more than once.My $ was refunded in a timely manner too.It was a shame I never got it for my daughter - it would of looked great with her OUTFIT for Dr. Seuss WEEK at school.Most original.Maybe next time.\", \n",
    "       \"I already own this particular Shining Image jewelry box in brown, so this was my second buy. It arrived with some of the leather scratched, even though it looked like I was the first one opening the box. This particular color pink also looked pretty bad in person. The quality of this box seemed lesser than the brown one I own.I returned this pink case for a refund without a problem.  Got another brown Shining Image jewelry case and it's fine!\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "\n",
    "for t in testes:\n",
    "    result = PreprocessamentoSemStopWords(t)\n",
    "    testes[i] = Stemming(result)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "freq_testes = vectorizer.transform(testes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fazendo a classificação com o modelo treinado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Neutral', 'Positive', 'Negative', 'Negative'],\n",
       "      dtype='<U8')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo.predict(freq_testes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Avaliando o modelo **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fazendo o cross validation do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resultados = cross_val_predict(modelo, freq_reviews, classifications, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Medindo a acurácia média do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.64536984930907271"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(classifications,resultados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Medidas de validação do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Positive       0.74      0.75      0.75     26655\n",
      "   Negative       0.68      0.60      0.64     26655\n",
      "    Neutral       0.53      0.58      0.56     26655\n",
      "\n",
      "avg / total       0.65      0.65      0.65     79965\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentimento=['Positive','Negative','Neutral']\n",
    "print (metrics.classification_report(classifications,resultados,sentimento))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Matriz de confusão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted  Negative  Neutral  Positive    All\n",
      "True                                         \n",
      "Negative      16108     8485      2062  26655\n",
      "Neutral        6243    15581      4831  26655\n",
      "Positive       1472     5265     19918  26655\n",
      "All           23823    29331     26811  79965\n"
     ]
    }
   ],
   "source": [
    "print(pd.crosstab(classifications, resultados, rownames=['True'], colnames=['Predicted'], margins=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Melhorando resultados com Bigrams**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(1,2))\n",
    "freq_reviews = vectorizer.fit_transform(reviews.ravel())\n",
    "modelo = MultinomialNB()\n",
    "modelo.fit(freq_reviews,classifications)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resultados = cross_val_predict(modelo, freq_reviews, classifications, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66218970799724874"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(classifications,resultados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Positive       0.77      0.76      0.76     26655\n",
      "   Negative       0.69      0.61      0.65     26655\n",
      "    Neutral       0.54      0.62      0.58     26655\n",
      "\n",
      "avg / total       0.67      0.66      0.66     79965\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentimento=['Positive','Negative','Neutral']\n",
    "print (metrics.classification_report(classifications,resultados,sentimento))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predito   Negative  Neutral  Positive    All\n",
      "Real                                        \n",
      "Negative     16384     8592      1679  26655\n",
      "Neutral       6028    16418      4209  26655\n",
      "Positive      1199     5306     20150  26655\n",
      "All          23611    30316     26038  79965\n"
     ]
    }
   ],
   "source": [
    "print (pd.crosstab(classifications, resultados, rownames=['Real'], colnames=['Predito'], margins=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

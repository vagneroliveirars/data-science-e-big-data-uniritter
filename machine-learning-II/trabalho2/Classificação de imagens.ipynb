{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6.5 |Anaconda, Inc.| (default, Apr 29 2018, 16:14:56) \n",
      "[GCC 7.2.0]\n"
     ]
    }
   ],
   "source": [
    "import sys; print (sys.version) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Dataset</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### paths to training and testing data\n",
    "train_path = 'dataset/train'\n",
    "test_path = 'dataset'\n",
    "\n",
    "### other parameters\n",
    "classes = [\"dog\", \"cat\"]\n",
    "num_classes = len(classes)\n",
    "\n",
    "### image dimensions\n",
    "img_width, img_height = 224, 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(path):\n",
    "    img = cv2.imread(path)\n",
    "    resized = cv2.resize(img, (img_width, img_height), cv2.INTER_LINEAR)\n",
    "    return resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train():\n",
    "    X_train = []\n",
    "    X_train_id = []\n",
    "    y_train = []\n",
    "    start_time = time.time()\n",
    "\n",
    "    print('Loading training images...')\n",
    "    folders = [\"dogs\", \"cats\"]\n",
    "    for fld in folders:\n",
    "        index = folders.index(fld)\n",
    "        print('Loading {} files (Index: {})'.format(fld, index))\n",
    "        path = os.path.join(train_path, fld, '*g')\n",
    "        files = glob.glob(path)\n",
    "        for fl in files:\n",
    "            flbase = os.path.basename(fl)\n",
    "            img = load_images(fl)\n",
    "            X_train.append(img)\n",
    "            X_train_id.append(flbase)\n",
    "            y_train.append(index)\n",
    "\n",
    "    print('Training data load time: {} seconds'.format(round(time.time() - start_time, 2)))\n",
    "    return X_train, y_train, X_train_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test():\n",
    "    X_test = []\n",
    "    X_test_id = []\n",
    "    y_test = []\n",
    "    start_time = time.time()\n",
    "\n",
    "    print('Loading test images...')\n",
    "    folders = [\"test\"]\n",
    "    for fld in folders:\n",
    "        index = folders.index(fld)\n",
    "        print('Loading {} files (Index: {})'.format(fld, index))\n",
    "        path = os.path.join(test_path, fld, '*g')\n",
    "        files = glob.glob(path)\n",
    "        for fl in files:\n",
    "            flbase = os.path.basename(fl)\n",
    "            img = load_images(fl)\n",
    "            X_test.append(img)\n",
    "            X_test_id.append(flbase)\n",
    "            y_test.append(index)\n",
    "\n",
    "    print('Test data load time: {} seconds'.format(round(time.time() - start_time, 2)))\n",
    "    return X_test, y_test, X_test_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_train_data():\n",
    "    train_data, train_target, train_id = load_train()\n",
    "\n",
    "    train_data = np.array(train_data, dtype=np.uint8)\n",
    "    train_target = np.array(train_target, dtype=np.uint8)\n",
    "\n",
    "    train_data = train_data.astype('float32')\n",
    "    train_data = train_data / 255\n",
    "    train_target = to_categorical(train_target, num_classes)\n",
    "\n",
    "    print('Shape of training data:', train_data.shape)\n",
    "    return train_data, train_target, train_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_test_data():\n",
    "    test_data, test_target, test_id = load_test()\n",
    "\n",
    "    test_data = np.array(test_data, dtype=np.uint8)\n",
    "    test_target = np.array(test_target, dtype=np.uint8)\n",
    "\n",
    "    test_data = test_data.astype('float32')\n",
    "    test_data = test_data / 255\n",
    "    test_target = to_categorical(test_target, num_classes)\n",
    "\n",
    "    print('Shape of testing data:', test_data.shape)\n",
    "    return test_data, test_target, test_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training images...\n",
      "Loading dogs files (Index: 0)\n",
      "Loading cats files (Index: 1)\n",
      "Training data load time: 14.65 seconds\n",
      "Shape of training data: (6000, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, train_id = normalize_train_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading test images...\n",
      "Loading test files (Index: 0)\n",
      "Test data load time: 6.72 seconds\n",
      "Shape of testing data: (1000, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "x_test, y_test, test_id = normalize_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#plt.imshow(x_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Criando uma CNN</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_node = Input(shape=(img_width, img_height, 3))\n",
    "\n",
    "conv_1 = Conv2D(filters=4, kernel_size=(3, 3), strides=1,\n",
    "                activation='relu')(input_node)\n",
    "pool_1 = MaxPooling2D(pool_size=(2, 2), strides=2)(conv_1)\n",
    "\n",
    "conv_2 = Conv2D(filters=8, kernel_size=(3, 3), strides=1,\n",
    "               activation='relu')(pool_1)\n",
    "pool_2 = MaxPooling2D(pool_size=(2, 2), strides=2)(conv_2)\n",
    "\n",
    "conv_3 = Conv2D(filters=16, kernel_size=(3, 3), strides=1,\n",
    "               activation='relu')(pool_2)\n",
    "conv_4 = Conv2D(filters=32, kernel_size=(3, 3), strides=1,\n",
    "               activation='relu')(conv_3)\n",
    "\n",
    "flat = Flatten()(conv_4)\n",
    "\n",
    "fc1 = Dense(num_classes, activation='softmax')(flat)\n",
    "\n",
    "model = Model(input_node, fc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 222, 222, 4)       112       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 111, 111, 4)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 109, 109, 8)       296       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 54, 54, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 52, 52, 16)        1168      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 50, 50, 32)        4640      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 80000)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 160002    \n",
      "=================================================================\n",
      "Total params: 166,218\n",
      "Trainable params: 166,218\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Compilando o modelo</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import *\n",
    "from keras.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer='Adam', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stop = EarlyStopping(min_delta=1e-3, monitor='val_loss', patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "6000/6000 [==============================] - 114s 19ms/step - loss: 0.6898 - acc: 0.5900 - val_loss: 0.5998 - val_acc: 0.6950\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe2518abda0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, \n",
    "          y_train, \n",
    "          batch_size=32, \n",
    "          epochs=1,\n",
    "          callbacks=[early_stop],\n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
